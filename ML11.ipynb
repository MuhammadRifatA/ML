{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadRifatA/ML/blob/main/ML11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas Praktikum"
      ],
      "metadata": {
        "id": "thZqOaAPyyWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Modifikasi model CNN pada praktikum 2 sehingga didapatkan akurasi testing lebih dari 80%.\n",
        "- Buatlah model CNN untuk klasifikasi dataset MNIST."
      ],
      "metadata": {
        "id": "ciqtdO7Sy1vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Klasifikasi dataset MNIST**"
      ],
      "metadata": {
        "id": "fAvIUOEN0PUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "vNXyxeEM4Itr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pra-pengolahan data MNIST"
      ],
      "metadata": {
        "id": "JKSgEIPU3kkX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hccpP2DkyDIV",
        "outputId": "7c1d3b1b-8f85-4b1a-97cd-8d417174544a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# Pra-pengolahan data\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "# memisahkan data gambar dengan label\n",
        "gambar = mnist.data.astype('float32')\n",
        "label = mnist.target.astype('int')\n",
        "\n",
        "# normalisasi rentang nilai piksel menjadi antara 1 dan 0\n",
        "gambar /= 255.0  # Skalakan data\n",
        "\n",
        "# Bagi data menjadi data pelatihan dan pengujian (split data)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    gambar, label, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buat Model CNN"
      ],
      "metadata": {
        "id": "p481qJcF6D9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# buat model dan layer konvolusi.\n",
        "# Layer Fully Connected (input) dan (output).\n",
        "model = models.Sequential(\n",
        "    [\n",
        "        layers.Reshape(target_shape=(28, 28, 1), input_shape=(784,)),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Hd8xpLPJ6Wvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kompilasi Model dan Melakukan Training model"
      ],
      "metadata": {
        "id": "bBZ4rNuY8cY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kompilasi model\n",
        "#\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3tEoc7k8mLu",
        "outputId": "405a0003-66c7-479f-a83b-9e61e87965a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1400/1400 [==============================] - 17s 5ms/step - loss: 0.1707 - accuracy: 0.9486 - val_loss: 0.0865 - val_accuracy: 0.9729\n",
            "Epoch 2/10\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.0531 - accuracy: 0.9835 - val_loss: 0.0593 - val_accuracy: 0.9813\n",
            "Epoch 3/10\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.0530 - val_accuracy: 0.9827\n",
            "Epoch 4/10\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.0499 - val_accuracy: 0.9849\n",
            "Epoch 5/10\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0552 - val_accuracy: 0.9844\n",
            "Epoch 6/10\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0595 - val_accuracy: 0.9848\n",
            "Epoch 7/10\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0609 - val_accuracy: 0.9843\n",
            "Epoch 8/10\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0510 - val_accuracy: 0.9868\n",
            "Epoch 9/10\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0670 - val_accuracy: 0.9844\n",
            "Epoch 10/10\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0640 - val_accuracy: 0.9864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluasi Model"
      ],
      "metadata": {
        "id": "ZGn9Q1sg8565"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluasi akurasi data testing\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Akurasi pada data testing: {test_acc:.2f}')\n",
        "\n",
        "# evaluasi akurasi data training\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
        "print(f'Akurasi pada data training: {train_acc:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U95lblvn9N3w",
        "outputId": "067496ca-4df5-48d5-d7f9-acd709872854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9855\n",
            "Akurasi pada data testing: 0.99\n",
            "1750/1750 [==============================] - 5s 3ms/step - loss: 0.0155 - accuracy: 0.9964\n",
            "Akurasi pada data training: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix untuk Data Tesing"
      ],
      "metadata": {
        "id": "pHhVe_xgdJvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Membuat prediksi pada data testing\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Membuat matriks kebingungan\n",
        "confusion = confusion_matrix(test_labels, predicted_labels)\n",
        "print('Confusion Matrix:')\n",
        "print(confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_vlbRRBdVqQ",
        "outputId": "b638cf0b-c800-416d-af3e-989df6c3e3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 1s 2ms/step\n",
            "Confusion Matrix:\n",
            "[[1333    1    1    1    1    1    2    0    2    1]\n",
            " [   0 1586    1    1    3    0    1    3    0    5]\n",
            " [   1    3 1365    0    1    0    1    3    5    1]\n",
            " [   1    0    8 1406    0    7    0    2    4    5]\n",
            " [   0    0    0    0 1280    0    0    1    0   14]\n",
            " [   1    0    1    5    0 1263    2    0    1    0]\n",
            " [   2    3    0    0    1    1 1389    0    0    0]\n",
            " [   2    1    7    1    8    1    0 1475    1    7]\n",
            " [   2    3    5    5    4    7    5    4 1309   13]\n",
            " [   3    0    0    2   11    5    0    5    3 1391]]\n"
          ]
        }
      ]
    }
  ]
}